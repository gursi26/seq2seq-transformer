{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6i9wNNW551BR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from dataset import EngSpaDataset\n",
        "from model import Seq2SeqTransformer\n",
        "from utils import inference, TransformerSchedulerOptimizer, PadCollate, prepare_mask, save_state, load_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "533kuQGh51Ba"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "LR = 1e-9\n",
        "BATCH_SIZE = 128\n",
        "BETAS = [0.9, 0.98]\n",
        "WARMUP_STEPS = 4000\n",
        "START_EPOCH = 1\n",
        "EPOCHS = 100\n",
        "CLIP_VALUE = 0.5\n",
        "\n",
        "# Model hyperparameters\n",
        "D_MODEL = 512\n",
        "NUM_HEADS = 8\n",
        "ENC_LAYERS = 6\n",
        "DEC_LAYERS = 6\n",
        "\n",
        "# Other\n",
        "DATASET_PATH = \"eng-spa.csv\"\n",
        "SAVE_PATH = \"\"\n",
        "DEV = torch.device(\"mps\")\n",
        "\n",
        "\n",
        "dataset = EngSpaDataset(DATASET_PATH)\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=PadCollate())\n",
        "crit = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Seq2SeqTransformer(\n",
        "        src_dim=len(dataset.eng2idx),\n",
        "        tgt_dim=len(dataset.spa2idx),\n",
        "        d_model=D_MODEL,\n",
        "        num_heads=NUM_HEADS,\n",
        "        enc_layers=ENC_LAYERS,\n",
        "        dec_layers=DEC_LAYERS\n",
        "    ).to(DEV)\n",
        "\n",
        "opt = optim.Adam(model.parameters(), lr=LR, betas=BETAS)\n",
        "scheduler = TransformerSchedulerOptimizer(opt, WARMUP_STEPS, D_MODEL) # combined scheduler and optimizer\n",
        "\n",
        "\n",
        "# model, scheduler, START_EPOCH = load_state(SAVE_PATH + \"weights.pth\", DEV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "qkYOn7Bp51Ba",
        "outputId": "51e16f4b-08cb-4fda-ebf1-56902dd23c36"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch : [1/100]:   3%|â–Ž         | 33/1092 [00:08<04:44,  3.72it/s, avg_loss=158]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/m2/jysgcgj57vn69541g8m0qz_h0000gn/T/ipykernel_17522/1054146643.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# nn.utils.clip_grad_norm_(model.parameters(), CLIP_VALUE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for e in range(START_EPOCH, EPOCHS + 1):\n",
        "    loop = tqdm(enumerate(loader), total=len(loader))\n",
        "    loop.set_description(f\"Epoch : [{e}/{EPOCHS}]\")\n",
        "\n",
        "    total_loss = 0\n",
        "    model = model.train()\n",
        "\n",
        "    for i, ((src, src_mask), (dec_input, dec_mask), tgt) in loop:\n",
        "        # Prepare inputs\n",
        "        src, dec_input, tgt = src.to(DEV), dec_input.to(DEV), tgt.to(DEV)\n",
        "        src_mask = prepare_mask(src_mask).to(DEV)\n",
        "        dec_mask = prepare_mask(dec_mask, no_peek_future=True).to(DEV)\n",
        "\n",
        "        # Forward and backward pass\n",
        "        scheduler.zero_grad()\n",
        "        yhat = model(src, dec_input, src_mask, dec_mask)\n",
        "        loss = crit(yhat.view(-1, yhat.shape[-1]), tgt.view(-1))\n",
        "        loss.backward()\n",
        "        # nn.utils.clip_grad_norm_(model.parameters(), CLIP_VALUE)\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loop.set_postfix(avg_loss = total_loss / (i + 1))\n",
        "\n",
        "    # sample for eval\n",
        "    model = model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = inference(\"hello, how are you today?\", model, dataset, DEV)\n",
        "    print(f\"Epoch {e} : {pred}\")\n",
        "    save_state(SAVE_PATH + f\"transformer-final-{e}.pth\", model, scheduler, e)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "P0B0BN7V51BU",
        "SFRCa6OQ51BW",
        "JKY6kfc251BX",
        "Ce4oAlsY51BY",
        "eeCK_Oor51BZ",
        "ekvyyX1f51BZ"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
